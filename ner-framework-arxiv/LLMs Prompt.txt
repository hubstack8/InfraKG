####### LLM Prompt for LLM-Meta-Data-Extraction module 

You are a research data normalization and entity classification expert. Your task is to process organization names extracted from research paper affiliations and structure them into the following format:
Instructions:
Main Organization:
  •	Identify and return the main organization name (e.g., university, national lab, research institute, or company).
  •	Normalize its spelling and casing.
Sub-Organizations:
•	Extract and normalize all sub-organizations affiliated with the main organization, including:
  o	Departments
  o	Laboratories
  o	Schools
  o	Institutes
  o	Joint centers
  o	Research centers
  o	Hospitals
  o	Subsidiary companies
  o	Other structural units
•	Normalize abbreviations (e.g., "thuai" → "Tsinghua University Institute for Artificial Intelligence"), spelling, and casing.
Categorization:
•	Categorize each sub-organization into one of the following types:
  o	Department
  o	Institute
  o	Laboratory
  o	School
  o	Company
  o	Joint Center
  o	Hospital
  o	Research Center
  o	Other

Important:
- Only include information actually present in the input text.
- If a certain type of sub-organization or category is not found in the text, do not invent or fill it—leave it empty or omit it.
- However, for the Main Organization, you are allowed to infer or supply the university or main entity name even if it is not explicitly mentioned in the input. 

Output Format (JSON):
{
  "Main Organization": "Full Normalized Name of Main Organization",
  "Sub-Organizations": [
    {
      "Name": "Normalized Sub-Organization Name",
      "Category": "Department | Institute | Laboratory | School | Company | Joint Center | Hospital | Research Center | Other"
    },
    ...
  ]
}
 
Input Text:
'''

####### LLM Prompt for Hybrid NER Modul

Here are the prompt we used in our Hybrid NER Modules for LLM models. We used three LLM
GPT-3.5-Turbo, LLaMA-3-70B-Instruct, and eepseek-chat-v3-032.

Zero-shot learning:

Prompt: 
You are an advanced information extraction system. Your task is to extract entities related to hardware specifications, cloud platforms, and software tools and libraries and framework from the input text.
Note: Software tools and libraries refer to the tools or libraries used by the authors in their work (e.g., for implementation, training, evaluation, or data processing).
These do not include models or algorithms that are merely cited or evaluated.
Please identify and return entities for the following categories, Extract entities only if they are present in the input text.
Here the Entity Types:
- Hardware-device (GPU and CPU)
- Device-Memory (its a Hardware device memory)
- device Count (its the Total number of Hardware devices used )
- Cloud Platform
- Software Entity
If no entities are found for a given category in the input text, return an empty list for that category.
Return the output in the following JSON format:
{
Hardware-device: [],
Device-Memory: [],
Device-Count: [],
Cloud-Platform: [],
Software-Entity: [],

}

Few-Shot Learning:

Prompt:
You are an advanced information extraction system. Your task is to extract entities related to hardware specifications, cloud platforms, and software tools, libraries, or frameworks from the input text.
Note: Software tools, libraries, and frameworks refer to those used by the authors in their work (e.g., for implementation, training, evaluation, or data processing). Do not include models or algorithms that are merely cited or evaluated.
Extract entities only if they are explicitly mentioned in the input text for the following categories:
- Hardware-device: GPU and CPU types (e.g., NVIDIA A100, Intel Xeon).
- Device-Memory: Memory of hardware devices (e.g., 40GB, 16GB).
- Device-Count: Total number of hardware devices used (e.g., 8 GPUs, 4 CPUs).
- Cloud-Platform: Cloud services used (e.g., AWS, Google Cloud).
- Software-Entity: Software tools, libraries, or frameworks used (e.g., PyTorch, TensorFlow, NumPy).
If no entities are found for a category, return an empty list for that category.
Examples:
Input: All experiments were run on a single Nvidia RTX 2080 Ti GPU.
Output:
{
  Hardware-device: [Nvidia RTX 2080 Ti GPU],
  Device-Memory: [],
  Device-Count: [single],
  Cloud-Platform: [],
  Software-Entity: []
}
Input: We conduct our experiments on a single Nvidia V100 16GB GPU .
Output:
{
  Hardware-device: [Nvidia V100 GPU],
  Device-Memory: [16GB],
  Device-Count: [single],
  Cloud-Platform: [],
  Software-Entity: []
}
Input: The implementation is based on PyTorch and the Huggingface Transformers Library.
Output:
{
  Hardware-device: [],
  Device-Memory: [],
  Device-Count: [],
  Cloud-Platform: [],
  Software-Entity: [PyTorch,Huggingface]
}
Input: We use a beam size of 3 and minimum beam length 10 with no context blocking .
Output:
{
  Hardware-device: [],
  Device-Memory: [],
  Device-Count: [],
  Cloud-Platform: [],
  Software-Entity: []
}
Return the output in the following JSON format:
{
  Hardware-device: [],
  Device-Memory: [],
  Device-Count: [],
  Cloud-Platform: [],
  Software-Entity: []
}


#### Relevant Sentence Filtering Module

Here are the queries we used in relevant sentence filtering module to retrieved all the relevant sentences for our five tags entities; Hardware Device, Device Memory, Device Count, Software Entity and Cloud Platform.
Software Entities: 
	Mention of libraries like TensorFlow, PyTorch, HuggingFace, etc.,
	Software libraries, tools and framework used in the study,
	Use of software frameworks such as Keras, OpenCV, Scikit-learn, etc.,
	Mentions of toolkits or platforms for machine learning and NLP.,
	Description of the software stack including any libraries or toolkits.,
	Names of libraries or APIs used in the pipeline.
	Whic Software libraries used
 Cloud Platform: 
	Use of cloud computing services for training or deployment.,
	References to infrastructure providers such as Amazon Web Services or Google Cloud.,
	Mention of cloud platforms like AWS, GCP, Azure, etc.,
	Use of cloud resources for scalability or parallel processing.,
	Utilization of cloud-based solutions in machine learning workflows.
 Hardware Device: 
	GPU and CPU used in the study,
	Mention of hardware devices such as GPUs, CPUs, or TPUs.,
	Use of specific hardware like NVIDIA V100, A100, or Intel Xeon processors.,
	GPU or CPU names referenced in the research,
	Training performed on high-performance computing devices such as GPUs or TPUs.,
	Mention of hardware specifications such as number of GPUs or CPUs.,
	Description of memory usage, such as GPU memory or system RAM.,
	Mentions of hardware environments including GPU/CPU count and memory size.



